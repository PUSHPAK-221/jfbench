[build-system]
build-backend = "setuptools.build_meta"

requires = [ "setuptools>=61.1", "wheel" ]

[project]
name = "jfbench"
version = "0.1.0"

description = "Japanese instruction Following Benchmark"
readme = "README.md"
authors = [
  { name = "Hideaki Imamura" },
]
requires-python = ">=3.12,<3.14"
classifiers = [
  "Programming Language :: Python :: 3 :: Only",
  "Programming Language :: Python :: 3.12",
  "Programming Language :: Python :: 3.13",
]
dependencies = [
  "beautifulsoup4",
  "causal-conv1d==1.5.4; sys_platform=='linux' and platform_machine=='x86_64' and extra=='gpu'",
  "datasets",
  "emoji",
  "esprima",
  "flashinfer-cubin; sys_platform=='linux' and platform_machine=='x86_64' and extra=='gpu'",
  "flashinfer-python; sys_platform=='linux' and platform_machine=='x86_64' and extra=='gpu'",
  "html5lib",
  "httpx",
  "immutabledict",
  "janome",
  "mamba-ssm; sys_platform=='linux' and platform_machine=='x86_64' and extra=='gpu'",
  "markdown-it-py",
  "matplotlib",
  "nltk",
  "numba",
  "nvidia-ml-py; sys_platform=='linux' and platform_machine=='x86_64' and extra=='gpu'",
  "openai",
  "pandas",
  "pip",
  "plotly",
  "pre-commit",
  "pyarrow",
  "pylatexenc",
  "pymarkdownlnt",
  "pysbd",
  "pytest",
  "spacy",
  "syllapy",
  "tiktoken",
  "torch",
  "tqdm",
  "transformers",
  "trio",
  "vllm>=0.11; sys_platform=='linux' and platform_machine=='x86_64' and extra=='gpu'",
  "zstandard",
]

optional-dependencies = { gpu = [  ] }

[tool.setuptools]
package-dir = { "" = "src" }

[tool.setuptools.package-data]
jfbench = [ "data/ifbench_ja_translated.jsonl" ]

[tool.setuptools.packages.find]
where = [ "src" ]

[tool.ruff]
line-length = 99

lint.extend-select = [
  "I",
  "RUF",
  "SLF",
  "TC",
  "TID",
]

lint.ignore = [
  "RUF001",
  "RUF003",
]

lint.flake8-tidy-imports.ban-relative-imports = "parents"
lint.isort.force-single-line = true
lint.isort.force-sort-within-sections = true
lint.isort.lines-after-imports = 2
lint.isort.order-by-type = false

[tool.pytest.ini_options]
pythonpath = [ "src" ]

[tool.mypy]
warn_unused_ignores = true
# Options configure mypy's strict mode.
warn_unused_configs = true
disallow_untyped_calls = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
no_implicit_optional = true
warn_redundant_casts = true
strict_equality = true
extra_checks = true
no_implicit_reexport = true
ignore_missing_imports = true
explicit_package_bases = true
namespace_packages = true
exclude = [
  ".venv/",
  "venv/",
  "build/",
  "test_scripts/",
  ".*/.ipynb_checkpoints/.*",
]
mypy_path = [
  "src",
  "tests",
]

[[tool.mypy.overrides]]
module = [
  "jfbench.ifbench_translation",
  "jfbench.ifbench_translation.*",
]
ignore_errors = true

[tool.uv]
package = true
required-version = ">=0.6.11"
constraint-dependencies = [
  "kaleido!=0.2.1.post1; sys_platform!='manylinux2014_armv7l'", # workaround for uv error
]
no-build-package = [ "torch-cluster", "torch-scatter", "torch-sparse" ]

[tool.uv.sources]
causal-conv1d = [
  { url = "https://github.com/Dao-AILab/causal-conv1d/releases/download/v1.5.4/causal_conv1d-1.5.4%2Bcu12torch2.8cxx11abiTRUE-cp312-cp312-linux_x86_64.whl", marker = "python_version == '3.12' and sys_platform == 'linux' and platform_machine == 'x86_64' and extra == 'gpu'" },
  { url = "https://github.com/Dao-AILab/causal-conv1d/releases/download/v1.5.4/causal_conv1d-1.5.4%2Bcu12torch2.8cxx11abiTRUE-cp313-cp313-linux_x86_64.whl", marker = "python_version == '3.13' and sys_platform == 'linux' and platform_machine == 'x86_64' and extra == 'gpu'" },
]
nvidia-cublas-cu12 = { index = "torch", marker = "sys_platform == 'linux' and platform_machine == 'x86_64' and extra == 'gpu'" }
nvidia-cuda-cupti-cu12 = { index = "torch", marker = "sys_platform == 'linux' and platform_machine == 'x86_64' and extra == 'gpu'" }
nvidia-cuda-nvrtc-cu12 = { index = "torch", marker = "sys_platform == 'linux' and platform_machine == 'x86_64' and extra == 'gpu'" }
nvidia-cuda-runtime-cu12 = { index = "torch", marker = "sys_platform == 'linux' and platform_machine == 'x86_64' and extra == 'gpu'" }
nvidia-cudnn-cu12 = { index = "torch", marker = "sys_platform == 'linux' and platform_machine == 'x86_64' and extra == 'gpu'" }
nvidia-cufft-cu12 = { index = "torch", marker = "sys_platform == 'linux' and platform_machine == 'x86_64' and extra == 'gpu'" }
nvidia-curand-cu12 = { index = "torch", marker = "sys_platform == 'linux' and platform_machine == 'x86_64' and extra == 'gpu'" }
nvidia-cusolver-cu12 = { index = "torch", marker = "sys_platform == 'linux' and platform_machine == 'x86_64' and extra == 'gpu'" }
nvidia-cusparse-cu12 = { index = "torch", marker = "sys_platform == 'linux' and platform_machine == 'x86_64' and extra == 'gpu'" }
nvidia-nccl-cu12 = { index = "torch", marker = "sys_platform == 'linux' and platform_machine == 'x86_64' and extra == 'gpu'" }
nvidia-nvtx-cu12 = { index = "torch", marker = "sys_platform == 'linux' and platform_machine == 'x86_64' and extra == 'gpu'" }
torch = { index = "torch", marker = "sys_platform == 'linux' and platform_machine == 'x86_64' and extra == 'gpu'" }
torchaudio = { index = "torch", marker = "sys_platform == 'linux' and platform_machine == 'x86_64' and extra == 'gpu'" }
torchvision = { index = "torch", marker = "sys_platform == 'linux' and platform_machine == 'x86_64' and extra == 'gpu'" }
triton = { index = "torch", marker = "sys_platform == 'linux' and platform_machine == 'x86_64' and extra == 'gpu'" }

[[tool.uv.index]]
name = "torch"
url = "https://download.pytorch.org/whl/cu126"
explicit = true
